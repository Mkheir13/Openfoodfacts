# Open Food Facts - Analyse de Donn√©es et Clustering

Ce projet fournit une application web Streamlit pour analyser et appliquer des algorithmes de clustering sur les donn√©es de produits alimentaires d'Open Food Facts. Il permet aux utilisateurs de t√©l√©verser un jeu de donn√©es (ou d'utiliser un √©chantillon), de le pr√©traiter et d'appliquer divers algorithmes de clustering.

## ‚ú® Fonctionnalit√©s Principales

*   **Chargement et Pr√©traitement Interactif :** Chargez vos donn√©es CSV ou utilisez un √©chantillon. Appliquez des √©tapes de nettoyage et de pr√©paration configurables.
*   **Clustering Avanc√© :** Appliquez K-Means, DBSCAN, ou GMM avec optimisation des hyperparam√®tres et s√©lection des caract√©ristiques.
*   **Visualisation Intuitive :** Explorez les clusters via des graphiques PCA 2D et 3D, et analysez les caract√©ristiques distinctives de chaque groupe.
*   **Export et Sauvegarde :** T√©l√©chargez les donn√©es pr√©trait√©es et sauvegardez les mod√®les de clustering entra√Æn√©s.

## üöÄ Installation et Configuration

**Pr√©requis :**

*   Python (version 3.8+ recommand√©e)
*   pip (gestionnaire de paquets Python)
*   Git (pour cloner le d√©p√¥t)

**√âtapes :**

1.  **Cloner le d√©p√¥t :**
    ```bash
    git clone <url_du_depot>
    cd <repertoire_du_projet>
    ```

2.  **Cr√©er un Environnement Virtuel et Installer les D√©pendances :**
    Il est fortement recommand√© d'utiliser un environnement virtuel pour isoler les d√©pendances.
    *   **Cr√©ation :**
        ```bash
        python -m venv .venv
        ```
    *   **Activation :**
        *   Windows (PowerShell/CMD) : `.\.venv\Scripts\activate`
        *   Linux/macOS (bash/zsh) : `source .venv/bin/activate`
        *(L'invite de commande indiquera que l'environnement `.venv` est actif)*
    *   **Installation des d√©pendances :**
        ```bash
        pip install -r requirements.txt
        ```
    *   **D√©sactivation (quand termin√©) :** `deactivate`
    *(N'oubliez pas de r√©activer l'environnement pour utiliser le projet)*

3.  **Pr√©parer les Donn√©es :**
    *   **Option A : T√©l√©charger le jeu de donn√©es complet :** Le fichier `config.yaml` pointe vers le jeu de donn√©es anglais (`https://static.openfoodfacts.org/data/en.openfoodfacts.org.products.csv`). T√©l√©chargez-le et placez-le dans un dossier `data/`.
    *   **Option B : Cr√©er un √©chantillon :** Pour un d√©marrage rapide, utilisez le script `create_reduced_file.py` sur le fichier complet t√©l√©charg√©.
        ```bash
        # Cr√©e data/reduced/full_datas_100000.csv (100 000 lignes)
        python create_reduced_file.py data/en.openfoodfacts.org.products.csv 100000
        ```
        L'application proposera d'utiliser cet √©chantillon s'il est trouv√©.

## ‚ñ∂Ô∏è Utilisation de l'Application Streamlit

1.  **Lancer l'application :**
    Assurez-vous que votre environnement virtuel est activ√©, puis ex√©cutez :
    ```bash
    streamlit run app.py
    ```
    L'application s'ouvrira dans votre navigateur web (g√©n√©ralement `http://localhost:8501`).

2.  **Interface Utilisateur :**
    L'application est divis√©e en deux onglets principaux :
    *   `üìä Preprocessing`
    *   `üß† Clustering`

3.  **Onglet `üìä Preprocessing` :**
    *   **Chargement :**
        *   Utilisez le bouton "Browse files" pour t√©l√©verser votre propre fichier CSV (s√©parateur tabulation `\t` attendu).
        *   Si un fichier √©chantillon (`data/reduced/full_datas_100000.csv`) existe, un bouton "Utiliser le fichier √©chantillon par d√©faut" appara√Ætra. Cliquez dessus pour le charger.
        *   Un aper√ßu (`.head()`) des donn√©es charg√©es s'affiche.
    *   **Nettoyage et Pr√©traitement :**
        *   Ajustez les param√®tres de pr√©traitement dans la barre lat√©rale (Sidebar) si n√©cessaire :
            *   *Nombre max de cat√©gories* : Pour la conversion des variables cat√©gorielles.
            *   *Ratio min de valeurs uniques* : Pour la s√©lection de caract√©ristiques.
        *   Cliquez sur le bouton "Lancer le Preprocessing".
        *   Le processus effectue plusieurs √©tapes (extraction num√©rique, pr√©paration des caract√©ristiques pour le clustering) avec des indicateurs de progression (`spinner`).
        *   Un **R√©sum√© du Nettoyage** s'affiche (dimensions avant/apr√®s, colonnes/lignes supprim√©es).
        *   **Sauvegarder les donn√©es :** Les donn√©es pr√©trait√©es sont automatiquement sauvegard√©es dans `data/preprocessed/` (ex: `full_datas_100000_preprocessed.csv`).
        *   Un bouton **"T√©l√©charger le CSV Pr√©trait√©"** appara√Æt pour r√©cup√©rer ce fichier.
    *   Un aper√ßu des donn√©es pr√©trait√©es est affich√©. Vous pouvez maintenant passer √† l'onglet Clustering.

4.  **Onglet `üß† Clustering` :**
    *   **Chargement des donn√©es pr√©trait√©es :**
        *   Si vous venez de terminer le pr√©traitement dans l'onglet pr√©c√©dent, les donn√©es sont d√©j√† charg√©es.
        *   Sinon, un avertissement appara√Æt. Vous pouvez t√©l√©verser un fichier CSV **pr√©trait√©** existant via le bouton "Browse files".
    *   **Configuration :**
        *   **S√©lection des Colonnes :** Choisissez les colonnes num√©riques (pr√©alablement nettoy√©es et mises √† l'√©chelle implicitement par la suite) √† utiliser pour le clustering dans la liste d√©roulante `multiselect`.
        *   **Choix de l'Algorithme :** S√©lectionnez "K-Means", "DBSCAN", ou "GMM" dans la liste d√©roulante `selectbox`.
        *   **Configuration de l'Algorithme :** Des options sp√©cifiques apparaissent en fonction de l'algorithme choisi :
            *   **K-Means/GMM :**
                *   *Optimisation du nombre de clusters/composantes :* D√©finissez une plage (`min`/`max`) et une m√©thode d'√©valuation (`scoring_method` : silhouette, etc.). Cochez/d√©cochez la case pour activer/d√©sactiver la recherche automatique du nombre optimal.
                *   *Configuration de l'entra√Ænement :* D√©finissez le nombre de clusters/composantes (si l'optimisation est d√©sactiv√©e), la m√©thode d'optimisation des param√®tres (`optimize_method`), et d'autres hyperparam√®tres (max_iter, init, etc.).
                *   *Sauvegarde :* Cochez la case pour sauvegarder le mod√®le entra√Æn√© et sp√©cifiez le chemin (`.pkl`).
            *   **DBSCAN :**
                *   Ajustez `eps` et `min_samples` via les sliders.
    *   **Lancer le Clustering :** Cliquez sur le bouton "Lancer le Clustering [Nom de l'Algo]".
    *   **R√©sultats :**
        *   Le temps d'entra√Ænement est affich√©.
        *   Les m√©triques de performance (Score Silhouette, Calinski-Harabasz, Davies-Bouldin) sont pr√©sent√©es.
        *   Le nombre de clusters trouv√©s (et de points de bruit pour DBSCAN) est indiqu√©.
        *   **Visualisations :** Des graphiques PCA en 2D et 3D montrent la r√©partition des points color√©s par cluster.
        *   **Aper√ßu des Donn√©es :** Un tableau (`dataframe`) montre les premi√®res lignes des donn√©es avec la colonne `cluster` assign√©e.
        *   **Analyse des Clusters :** Pour chaque cluster trouv√©, les caract√©ristiques ayant les moyennes les plus √©lev√©es et les plus distinctives (par rapport √† la moyenne globale) sont list√©es pour aider √† interpr√©ter les groupes.

## üìÇ Structure du Projet

```
‚îú‚îÄ‚îÄ .venv/           # Environnement virtuel Python (si cr√©√© ici)
‚îú‚îÄ‚îÄ .streamlit/      # Configuration Streamlit (si existante)
‚îú‚îÄ‚îÄ data/            # Fichiers de donn√©es (brutes, r√©duites, pr√©trait√©es)
‚îÇ   ‚îú‚îÄ‚îÄ reduced/       # Jeux de donn√©es √©chantillonn√©s
‚îÇ   ‚îî‚îÄ‚îÄ preprocessed/  # Jeux de donn√©es pr√©trait√©s sauvegard√©s
‚îú‚îÄ‚îÄ models/          # Mod√®les de clustering sauvegard√©s
‚îú‚îÄ‚îÄ notebooks/       # Notebooks Jupyter pour l'exploration (si existants)
‚îú‚îÄ‚îÄ results/         # R√©sultats d'analyse (si sauvegard√©s)
‚îú‚îÄ‚îÄ scripts/         # Modules Python principaux
‚îÇ   ‚îú‚îÄ‚îÄ data/        # Scripts de chargement, nettoyage, √©chantillonnage des donn√©es
‚îÇ   ‚îú‚îÄ‚îÄ features/    # Scripts d'ing√©nierie des caract√©ristiques (scaling, etc.)
‚îÇ   ‚îî‚îÄ‚îÄ models/      # Impl√©mentations des algorithmes de clustering
‚îú‚îÄ‚îÄ tests/           # Tests unitaires et d'int√©gration
‚îú‚îÄ‚îÄ .gitignore       # Fichiers/dossiers ignor√©s par Git
‚îú‚îÄ‚îÄ app.py           # Fichier principal de l'application Streamlit
‚îú‚îÄ‚îÄ config.yaml      # Configuration (ex: chemins des donn√©es)
‚îú‚îÄ‚îÄ create_reduced_file.py # Script pour cr√©er des √©chantillons de donn√©es
‚îú‚îÄ‚îÄ MANIFEST.in      # Fichier manifeste pour le packaging
‚îú‚îÄ‚îÄ README.md        # Ce fichier
‚îú‚îÄ‚îÄ requirements.txt # D√©pendances Python
‚îú‚îÄ‚îÄ setup.py         # Script pour packager le projet
‚îî‚îÄ‚îÄ ...              # Autres fichiers de configuration
```
